%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
%\documentclass[smallextended]{svjour3}       % onecolumn (second format)
\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
\usepackage{url}
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%
\begin{document}

\title{Dynamic Virtualized Deployment of Particle Physics Environments on a
  High-Performance Computing Cluster%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{Felix B\"uhrer \and Anton Gamel  \and Michael Janczyk \and
  Markus Schumacher \and
  Ulrike Schnoor \and Bernd Wiebelt \and People from KIT
  % etc.
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{U. Schnoor \at
              CERN \\
              \email{ulrike.schnoor@cern.ch}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           \and
           F. B\"uhrer \at
              Universit\"at Freiburg
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
Particle Physics experiments at the Large Hadron Collider (LHC) need a high
amount of computing resources for data processing, simulation, and analysis.
High-Performance Computing (HPC) resources provided by universities
can be useful supplements to the existing World-wide LHC Computing Grid resources
allocated by the collaboration. At the university of Frei\-burg, the
shared HPC cluster "NEMO" has been made available to ATLAS and CMS
users accessing NEMO from external collaboration-specific resources.
 To this effect, the full environment corresponding to a WLCG center
 is provided. The interplay between the NEMO and the external
 resources' schedulers is ensured through the ROCED service.
An OpenStack infrastructure is deployed at NEMO to orchestrate the
simultaneous usage for bare metal and virtualized jobs.
Through the setup, resources are provided to users in an automatized,
on-demand way. The performance of the virtualized environment has been
evaluated for particle physics jobs.

%Insert your abstract here. Include keywords, PACS and mathematical
%subject classification numbers as needed.
\keywords{Virtualization \and Particle Physics \and Grid Computing \and More keywords}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}




\section{Introduction}
\label{intro}
\input{include/Introduction.tex}

\section{Virtualization infrastructure}
\label{sec:openstack}
$\to$Rechenzentrum\\
\input{include/Infrastructure.tex}
\section{Generation of the image}
The research environments in the use case described in this paper are OpenStack containers in the
format of compatible VM images.
These images are provided in an automatized
way allowing versioning and archiving of the environments captured in
the images. The approaches used in the
different groups are described in the following.

\subsection{Packer combined with Puppet}
$\to$ATLAS Freiburg\\
\input{include/PackerPuppet.tex}



\subsection{Image generation using the Oz toolkit}
%$\to$CMS Karlsruhe\\
\input{include/KarlsruheImageGen.tex}

\section{Interfacing the schedulers using ROCED}
Introduction about the requirements for an in-between layer
\\$\to $ Karlsruhe
\subsection{ROCED}
\begin{figure*}
\begin{center}
  \includegraphics[width=0.9\linewidth]{figures/roced_design_flat.pdf}
  \caption{Overview of the ROCED modular design. The ROCED Core contains the Broker which decides when and on which sites new virtual machines are booted. The Requirement Adapters report about the utilization and resource requirements of the attached batch systems. The Site Adapter is responsible to manage the lifetime of virtual machines on an cloud site and the Integration Adapter ensure that newly booted machines are integrated into the batch system.}
  \label{fig-frplots}
\end{center}
\end{figure*}

%$\to$ CMS Karlsruhe
The cloud meta-scheduler ROCED (Responsive On-demand Cloud Enabled Deployment) has been developed at the KIT since 2010~\cite{ROCED}. ROCED is written in a modular
fashion and the interfaces to batch systems and cloud sites are implemented as so-called \textit{Adapters}. This makes ROCED independent of a specific user group or workflow. It provides a scheduling core which collects the current requirement of computing resources and decides if virtual machines need to be started or can be stopped. One or more Requirement Adapters report the current queue status of batch systems to the central scheduling core. Currently, Requirement Adapters are implemented for the Slurm, Torque, HTCondor and GridEngine batch systems. The Site Adapters allow ROCED to start, stop and monitor virtual machines on multiple cloud sites. Implementations exist for Amazon EC2, OpenStack, OpenNebula and Maob-based virtualization at HPC centers. Special care has been put into the resilience of ROCED: it can automatically terminate non-responsive machines and restart virtual machines in case some machines dropped out. This allows VM setups orchestrated by ROCED with thousands of virtual machines and many tens of thousands of jobs to run in production environments.


\subsection{Using HTCondor as front-end scheduler}\label{sec:ROCED:HTCondor}
%$\to$ CMS Karlsruhe
\input{include/HTCondor.tex}

\subsection{Using SLURM as front-end scheduler}
$\to$ ATLAS Freiburg\\
\input{include/Slurm.tex}


\section{Analysis of performance and usage}

The approach described so far has been implemented and put into
production in the research groups at University of Freiburg
(Physikalisches Institut) and Karlsruhe (... Institut).
The following chapter presents statistical results of the analysis of
the performance of the virtualized setup both in terms of job
performance as well as usage statistics.


\subsection{HEPSPEC benchmarks}
$\to$ ATLAS Freiburg\\
\input{include/Hepspec.tex}



\subsection{Production of simulation data}
$\to$ATLAS Freiburg
\\\input{include/Simulationtests.tex}

\subsection{Data analysis}
$\to$ATLAS Freiburg 

\subsection{Usage statistics}
Figure \ref{fig-frplots} show the utilization of virtual machines which were orchestraded by ROCED depending on the resource demands of the users of the KIT group. At peak times, up to 9000 virtual cores were filled with user jobs, which is more than half of the 16.000 cores of the NEMO cluster. 

\begin{figure}
\begin{center}
  \includegraphics[width=0.9\linewidth]{figures/NEMO_KIT_utiliztion.pdf}
  \caption{Utilization of the shared HPC system by booted virtual machines. Up to 9000 virtual cores were in use at peak times. The fluctuations in the utilization reflects the patterns of the submission of jobs by our institute users. The number of draining slots displays the amount of job slots still processing jobs while the rest of the node's slot are already empty.}
  \label{fig-frplots}
\end{center}
\end{figure}


\section{Conclusions and Outlook}
\input{include/Conclusions}

A system for the dynamic, on-demand provisioning of virtual machines
to run jobs in a High-Energy Physics context on an external, not
dedicated resource as realized at the HPC
cluster ``NEMO'' at University of Freiburg has been described. 
Reasons for the need for an interface between the schedulers of the host system
and the external system from which requests are sent have been
explained. 
The performance and usage have been analyzed for two groups. 

This approach can be generalized to other platforms and possibly also
other forms of virtualized environments (containers).
















%\subsection{Subsection title}
%\label{sec:2}
%as required. Don't forget to give each section
%and subsection a unique label (see Sect.~\ref{sec:1}).

%\paragraph{Paragraph headings} Use paragraph headings as needed.
%\begin{equation}
%a^2+b^2=c^2
%\end{equation}
%
%% For one-column wide figures use
%\begin{figure}
%% Use the relevant command to insert your figure file.
%% For example, with the graphicx package use
%  \includegraphics{example.eps}
%% figure caption is below the figure
%\caption{Please write your figure caption here}
%\label{fig:1}       % Give a unique label
%\end{figure}
%%
%% For two-column wide figures use
%\begin{figure*}
%% Use the relevant command to insert your figure file.
%% For example, with the graphicx package use
%  \includegraphics[width=0.75\textwidth]{example.eps}
%% figure caption is below the figure
%\caption{Please write your figure caption here}
%\label{fig:2}       % Give a unique label
%\end{figure*}
%
%% For tables use
%\begin{table}
%% table caption is above the table
%\caption{Please write your table caption here}
%\label{tab:1}       % Give a unique label
%% For LaTeX tables use
%\begin{tabular}{lll}
%\hline\noalign{\smallskip}
%first & second & third  \\
%\noalign{\smallskip}\hline\noalign{\smallskip}
%number & number & number \\
%number & number & number \\
%\noalign{\smallskip}\hline
%\end{tabular}
%\end{table}


%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{}   % name your BibTeX data base

% Non-BibTeX users please use
\begin{thebibliography}{}
%
% and use \bibitem to create references. Consult the Instructions
% for authors for reference list style.
%
\bibitem{Openstack}
OpenStack Open Source Cloud Computing Software
\url{https://www.openstack.org/}, accessed 2017-01-10

\bibitem{ROCED}
ROCED Cloud Meta-Scheduler project website
\url{https://github.com/roced-scheduler/ROCED}, accessed 2017-01-10

\bibitem{OZ}
Oz image generation toolkit
\url{https://github.com/clalancette/oz}, accessed 2017-01-10

\bibitem{HTCondor}
HTCondor workload manager
\url{https://research.cs.wisc.edu/htcondor/}, accessed 2017-01-10

\bibitem{packer}

Packer: tool for creating machine and container images for multiple platforms from a single source configuration. 
\url{https://www.packer.io/}, accessed 2017-01-13

\bibitem{puppet}

Puppet Enterprise. ``IT automation for cloud, security, and DevOps.''
\url{https://puppet.com/}, accessed 2017-01-10

\bibitem{SlurmElastic}
Slurm Elastic Computing ....


\bibitem{hpc-symp:2016}
Dirk von Suchodoletz, Bernd Wiebelt, Konrad Meier,Michael Janczyk,
  Flexible HPC: bwForCluster NEMO, 
Proceedings of the 3rd bwHPC-Symposium: Heidelberg 2016, \url{http://books.ub.uni
heidelberg.de/heibooks/reader/download/308/308-4-79237-1-10-20171002.pdf}

%title={Flexible HPC: bwForCluster NEMO},
%authors={Dirk von Suchodoletz and Bernd Wiebelt and Konrad Meier and
%Michael Janczyk},
%editors={Richling, Sabine and Baumann, Martin and Heuveline, Vincent},
%booktitle={Proceedings of the 3rd bwHPC-Symposium: Heidelberg 2016},
%publisher={heiBOOKS},
%year={2017},
%DOI={10.11588/heibooks.308.418},
%url={http://books.ub.uni
%heidelberg.de/heibooks/reader/download/308/308-4-79237-1-10-20171002.pdf}
%}

%\bibitem{RefJ}
% Format for Journal Reference
%Author, Article title, Journal, Volume, page numbers (year)
% Format for books
%\bibitem{RefB}
%Author, Book title, page numbers. Publisher, place (year)
% etc
\end{thebibliography}

\end{document}
% end of file template.tex

